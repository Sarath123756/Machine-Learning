{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All Techniques of Hyper Parameter Optimization\n",
    "\n",
    "1. GridSearchCV\n",
    "2. RandomizedSearchCV\n",
    "3. Bayesian Optimization -Automate Hyperparameter Tuning (Hyperopt)\n",
    "4. Sequential Model Based Optimization(Tuning a scikit-learn estimator with skopt)\n",
    "5. Optuna- Automate Hyperparameter Tuning\n",
    "6. Genetic Algorithms (TPOT Classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings \n",
    "warnings.filterwarnings (action= 'ignore')\n",
    "plt.style.use(['seaborn-bright' , 'dark_background'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"diabetes.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148.0</td>\n",
       "      <td>72</td>\n",
       "      <td>35.0</td>\n",
       "      <td>30.5</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85.0</td>\n",
       "      <td>66</td>\n",
       "      <td>29.0</td>\n",
       "      <td>30.5</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183.0</td>\n",
       "      <td>64</td>\n",
       "      <td>23.0</td>\n",
       "      <td>30.5</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89.0</td>\n",
       "      <td>66</td>\n",
       "      <td>23.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>40</td>\n",
       "      <td>35.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6    148.0             72           35.0     30.5  33.6   \n",
       "1            1     85.0             66           29.0     30.5  26.6   \n",
       "2            8    183.0             64           23.0     30.5  23.3   \n",
       "3            1     89.0             66           23.0     94.0  28.1   \n",
       "4            0    137.0             40           35.0    168.0  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Glucose'] = np.where(data['Glucose'] == 0 , data['Glucose'].median() , data['Glucose'])\n",
    "data['Insulin'] = np.where(data['Insulin'] == 0 , data['Insulin'].median() , data['Insulin'])\n",
    "data['SkinThickness'] = np.where(data['SkinThickness'] == 0 , data['SkinThickness'].median() , data['SkinThickness'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[: , :-1]\n",
    "Y = data.iloc[: , -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split as tts\n",
    "x_train , x_test , y_train , y_test = tts(X, Y , test_size=0.2 , random_state=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(n_estimators=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" checked><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_estimators=10)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(n_estimators=10)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(n_estimators= 10)\n",
    "classifier.fit(x_train , y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    500\n",
       "1    268\n",
       "Name: Outcome, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[86 13]\n",
      " [32 23]]\n",
      "0.7077922077922078\n"
     ]
    }
   ],
   "source": [
    "y_pred = classifier.predict(x_test)\n",
    "from sklearn.metrics import confusion_matrix , accuracy_score\n",
    "C_M = confusion_matrix(y_test , y_pred)\n",
    "print(C_M)\n",
    "print(accuracy_score(y_test , y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Grid "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'max_features': ['auto', 'sqrt', 'log2'], 'max_depth': [10, 120, 230, 340, 450, 560, 670, 780, 890, 1000], 'min_samples_split': [2, 5, 10, 14], 'min_samples_leaf': [1, 2, 4, 6, 8], 'criterion': ['entropy', 'gini']}\n"
     ]
    }
   ],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(200 , 2000 , 10)]\n",
    "# Number of features to consider at every split \n",
    "max_features = ['auto' , 'sqrt' , 'log2']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10 , 1000 , 10)]\n",
    "# Maximum number of samples required to split a node\n",
    "min_samples_split = [2 , 5, 10 , 14]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4, 6 , 8]\n",
    "# Create the Random Grid\n",
    "random_grid = {'n_estimators' : n_estimators,\n",
    "               'max_features' : max_features,\n",
    "               'max_depth' : max_depth,\n",
    "               'min_samples_split' : min_samples_split,\n",
    "               'min_samples_leaf' : min_samples_leaf,\n",
    "               'criterion' : ['entropy' , 'gini']}\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomized Search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 10 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kushalbanda/Anaconda/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=entropy, max_depth=1000, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.3s\n",
      "[CV] END criterion=entropy, max_depth=1000, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kushalbanda/Anaconda/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=6, min_samples_split=14, n_estimators=200; total time=   0.3s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=6, min_samples_split=14, n_estimators=200; total time=   0.3s\n",
      "[CV] END criterion=gini, max_depth=670, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=600; total time=   0.8s\n",
      "[CV] END criterion=gini, max_depth=670, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=600; total time=   0.8s\n",
      "[CV] END criterion=gini, max_depth=120, max_features=sqrt, min_samples_leaf=6, min_samples_split=5, n_estimators=1400; total time=   1.6s\n",
      "[CV] END criterion=gini, max_depth=120, max_features=sqrt, min_samples_leaf=6, min_samples_split=5, n_estimators=1400; total time=   1.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kushalbanda/Anaconda/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/kushalbanda/Anaconda/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=gini, max_depth=340, max_features=sqrt, min_samples_leaf=1, min_samples_split=14, n_estimators=2000; total time=   2.3s\n",
      "[CV] END criterion=gini, max_depth=340, max_features=sqrt, min_samples_leaf=1, min_samples_split=14, n_estimators=2000; total time=   2.4s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=14, n_estimators=2000; total time=   2.6s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=14, n_estimators=2000; total time=   2.5s\n",
      "[CV] END criterion=gini, max_depth=340, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=1400; total time=   1.6s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=600; total time=   0.6s\n",
      "[CV] END criterion=gini, max_depth=340, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=1400; total time=   1.7s\n",
      "[CV] END criterion=entropy, max_depth=670, max_features=log2, min_samples_leaf=6, min_samples_split=10, n_estimators=2000; total time=   2.3s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=600; total time=   0.7s\n",
      "[CV] END criterion=entropy, max_depth=670, max_features=log2, min_samples_leaf=6, min_samples_split=10, n_estimators=2000; total time=   2.3s\n",
      "[CV] END criterion=entropy, max_depth=1000, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=1400; total time=   1.5s\n",
      "[CV] END criterion=entropy, max_depth=1000, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=1400; total time=   1.4s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=2, estimator=RandomForestClassifier(), n_jobs=-1,\n",
       "                   param_distributions={&#x27;criterion&#x27;: [&#x27;entropy&#x27;, &#x27;gini&#x27;],\n",
       "                                        &#x27;max_depth&#x27;: [10, 120, 230, 340, 450,\n",
       "                                                      560, 670, 780, 890,\n",
       "                                                      1000],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;,\n",
       "                                                         &#x27;log2&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 4, 6, 8],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 5, 10, 14],\n",
       "                                        &#x27;n_estimators&#x27;: [200, 400, 600, 800,\n",
       "                                                         1000, 1200, 1400, 1600,\n",
       "                                                         1800, 2000]},\n",
       "                   random_state=100, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=2, estimator=RandomForestClassifier(), n_jobs=-1,\n",
       "                   param_distributions={&#x27;criterion&#x27;: [&#x27;entropy&#x27;, &#x27;gini&#x27;],\n",
       "                                        &#x27;max_depth&#x27;: [10, 120, 230, 340, 450,\n",
       "                                                      560, 670, 780, 890,\n",
       "                                                      1000],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;,\n",
       "                                                         &#x27;log2&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 4, 6, 8],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 5, 10, 14],\n",
       "                                        &#x27;n_estimators&#x27;: [200, 400, 600, 800,\n",
       "                                                         1000, 1200, 1400, 1600,\n",
       "                                                         1800, 2000]},\n",
       "                   random_state=100, verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=2, estimator=RandomForestClassifier(), n_jobs=-1,\n",
       "                   param_distributions={'criterion': ['entropy', 'gini'],\n",
       "                                        'max_depth': [10, 120, 230, 340, 450,\n",
       "                                                      560, 670, 780, 890,\n",
       "                                                      1000],\n",
       "                                        'max_features': ['auto', 'sqrt',\n",
       "                                                         'log2'],\n",
       "                                        'min_samples_leaf': [1, 2, 4, 6, 8],\n",
       "                                        'min_samples_split': [2, 5, 10, 14],\n",
       "                                        'n_estimators': [200, 400, 600, 800,\n",
       "                                                         1000, 1200, 1400, 1600,\n",
       "                                                         1800, 2000]},\n",
       "                   random_state=100, verbose=2)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "Random_Search_CV = RandomizedSearchCV(estimator= RandomForestClassifier() , param_distributions= random_grid , n_iter = 10 , cv = 2 , verbose = 2 , random_state= 100 , n_jobs = -1) \n",
    "Random_Search_CV.fit(x_train , y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 600,\n",
       " 'min_samples_split': 2,\n",
       " 'min_samples_leaf': 1,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': 120,\n",
       " 'criterion': 'entropy'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Random_Search_CV.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7752442996742671"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Random_Search_CV.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Param Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': ['entropy', 'entropy'], 'max_depth': [120], 'max_features': ['sqrt'], 'min_samples_leaf': [1, 3, 5], 'min_samples_split': [0, 3, 2], 'n_estimators': [400, 700, 600]}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'criterion' : [Random_Search_CV.best_params_['criterion'] , 'entropy'],\n",
    "    'max_depth' : [Random_Search_CV.best_params_['max_depth']],\n",
    "    'max_features' : [Random_Search_CV.best_params_['max_features']],\n",
    "    'min_samples_leaf' : [Random_Search_CV.best_params_['min_samples_leaf'],\n",
    "                          Random_Search_CV.best_params_['min_samples_leaf'] + 2,\n",
    "                          Random_Search_CV.best_params_['min_samples_leaf'] + 4],\n",
    "    'min_samples_split' : [Random_Search_CV.best_params_['min_samples_split'] - 2,\n",
    "                           Random_Search_CV.best_params_['min_samples_split'] + 1,\n",
    "                           Random_Search_CV.best_params_['min_samples_split']],\n",
    "    'n_estimators' : [Random_Search_CV.best_params_['n_estimators'] - 200,\n",
    "                      Random_Search_CV.best_params_['n_estimators'] + 100,\n",
    "                      Random_Search_CV.best_params_['n_estimators']]\n",
    "}\n",
    "print(param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 54 candidates, totalling 108 fits\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=sqrt, min_samples_leaf=1, min_samples_split=0, n_estimators=400; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=sqrt, min_samples_leaf=1, min_samples_split=0, n_estimators=400; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=sqrt, min_samples_leaf=1, min_samples_split=0, n_estimators=700; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=sqrt, min_samples_leaf=1, min_samples_split=0, n_estimators=600; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=sqrt, min_samples_leaf=1, min_samples_split=0, n_estimators=600; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=sqrt, min_samples_leaf=1, min_samples_split=0, n_estimators=700; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=400; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=400; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=400; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=400; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=sqrt, min_samples_leaf=3, min_samples_split=0, n_estimators=400; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=700; total time=   0.7s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=sqrt, min_samples_leaf=3, min_samples_split=0, n_estimators=400; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=600; total time=   0.7s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=700; total time=   0.9s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=600; total time=   0.8s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=sqrt, min_samples_leaf=3, min_samples_split=0, n_estimators=700; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=sqrt, min_samples_leaf=3, min_samples_split=0, n_estimators=600; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=sqrt, min_samples_leaf=3, min_samples_split=0, n_estimators=700; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=sqrt, min_samples_leaf=3, min_samples_split=0, n_estimators=600; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=700; total time=   0.9s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=600; total time=   0.7s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, n_estimators=400; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=400; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=700; total time=   1.1s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, n_estimators=600; total time=   0.7s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, n_estimators=700; total time=   0.8s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=sqrt, min_samples_leaf=5, min_samples_split=0, n_estimators=400; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, n_estimators=400; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=sqrt, min_samples_leaf=5, min_samples_split=0, n_estimators=400; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=sqrt, min_samples_leaf=5, min_samples_split=0, n_estimators=700; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=400; total time=   0.4s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=700; total time=   0.9s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=600; total time=   0.7s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=sqrt, min_samples_leaf=5, min_samples_split=0, n_estimators=600; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=600; total time=   0.8s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=sqrt, min_samples_leaf=5, min_samples_split=0, n_estimators=600; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=sqrt, min_samples_leaf=5, min_samples_split=0, n_estimators=700; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, n_estimators=600; total time=   0.7s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=sqrt, min_samples_leaf=5, min_samples_split=3, n_estimators=400; total time=   0.4s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, n_estimators=700; total time=   0.9s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=sqrt, min_samples_leaf=5, min_samples_split=2, n_estimators=400; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=600; total time=   0.7s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=sqrt, min_samples_leaf=1, min_samples_split=0, n_estimators=400; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=700; total time=   0.8s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=sqrt, min_samples_leaf=5, min_samples_split=3, n_estimators=400; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=sqrt, min_samples_leaf=1, min_samples_split=0, n_estimators=400; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=sqrt, min_samples_leaf=5, min_samples_split=3, n_estimators=700; total time=   0.8s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=sqrt, min_samples_leaf=5, min_samples_split=3, n_estimators=600; total time=   0.8s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=sqrt, min_samples_leaf=1, min_samples_split=0, n_estimators=600; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=sqrt, min_samples_leaf=1, min_samples_split=0, n_estimators=700; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=sqrt, min_samples_leaf=5, min_samples_split=2, n_estimators=400; total time=   0.4s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=sqrt, min_samples_leaf=5, min_samples_split=2, n_estimators=700; total time=   0.8s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=sqrt, min_samples_leaf=1, min_samples_split=0, n_estimators=600; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=sqrt, min_samples_leaf=1, min_samples_split=0, n_estimators=700; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=400; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=sqrt, min_samples_leaf=5, min_samples_split=2, n_estimators=600; total time=   0.9s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=sqrt, min_samples_leaf=5, min_samples_split=3, n_estimators=600; total time=   0.6s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=400; total time=   0.4s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=sqrt, min_samples_leaf=5, min_samples_split=3, n_estimators=700; total time=   0.8s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=400; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=600; total time=   0.8s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=sqrt, min_samples_leaf=5, min_samples_split=2, n_estimators=700; total time=   0.9s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=400; total time=   0.4s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=sqrt, min_samples_leaf=3, min_samples_split=0, n_estimators=400; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=700; total time=   1.0s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=sqrt, min_samples_leaf=3, min_samples_split=0, n_estimators=400; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=sqrt, min_samples_leaf=3, min_samples_split=0, n_estimators=700; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=sqrt, min_samples_leaf=3, min_samples_split=0, n_estimators=600; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=sqrt, min_samples_leaf=5, min_samples_split=2, n_estimators=600; total time=   0.8s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=sqrt, min_samples_leaf=3, min_samples_split=0, n_estimators=600; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=sqrt, min_samples_leaf=3, min_samples_split=0, n_estimators=700; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=700; total time=   0.8s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=600; total time=   0.7s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, n_estimators=400; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=600; total time=   0.8s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=400; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=700; total time=   0.9s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, n_estimators=600; total time=   0.7s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, n_estimators=700; total time=   0.8s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=600; total time=   0.7s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, n_estimators=400; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=700; total time=   0.8s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=sqrt, min_samples_leaf=5, min_samples_split=0, n_estimators=400; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=sqrt, min_samples_leaf=5, min_samples_split=0, n_estimators=400; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=sqrt, min_samples_leaf=5, min_samples_split=0, n_estimators=600; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=400; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=sqrt, min_samples_leaf=5, min_samples_split=0, n_estimators=700; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=sqrt, min_samples_leaf=5, min_samples_split=0, n_estimators=600; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=sqrt, min_samples_leaf=5, min_samples_split=0, n_estimators=700; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=700; total time=   0.9s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=600; total time=   0.8s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=sqrt, min_samples_leaf=5, min_samples_split=3, n_estimators=400; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, n_estimators=600; total time=   0.7s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=sqrt, min_samples_leaf=5, min_samples_split=3, n_estimators=400; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, n_estimators=700; total time=   0.9s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=sqrt, min_samples_leaf=5, min_samples_split=2, n_estimators=400; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=sqrt, min_samples_leaf=5, min_samples_split=3, n_estimators=700; total time=   0.9s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=sqrt, min_samples_leaf=5, min_samples_split=2, n_estimators=400; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=700; total time=   0.8s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=sqrt, min_samples_leaf=5, min_samples_split=3, n_estimators=700; total time=   0.9s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=sqrt, min_samples_leaf=5, min_samples_split=3, n_estimators=600; total time=   0.7s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=600; total time=   0.7s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=sqrt, min_samples_leaf=5, min_samples_split=3, n_estimators=600; total time=   0.7s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=sqrt, min_samples_leaf=5, min_samples_split=2, n_estimators=600; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=sqrt, min_samples_leaf=5, min_samples_split=2, n_estimators=600; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=sqrt, min_samples_leaf=5, min_samples_split=2, n_estimators=700; total time=   0.6s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=sqrt, min_samples_leaf=5, min_samples_split=2, n_estimators=700; total time=   0.6s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=2, estimator=RandomForestClassifier(), n_jobs=-1,\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;entropy&#x27;, &#x27;entropy&#x27;],\n",
       "                         &#x27;max_depth&#x27;: [120], &#x27;max_features&#x27;: [&#x27;sqrt&#x27;],\n",
       "                         &#x27;min_samples_leaf&#x27;: [1, 3, 5],\n",
       "                         &#x27;min_samples_split&#x27;: [0, 3, 2],\n",
       "                         &#x27;n_estimators&#x27;: [400, 700, 600]},\n",
       "             verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=2, estimator=RandomForestClassifier(), n_jobs=-1,\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;entropy&#x27;, &#x27;entropy&#x27;],\n",
       "                         &#x27;max_depth&#x27;: [120], &#x27;max_features&#x27;: [&#x27;sqrt&#x27;],\n",
       "                         &#x27;min_samples_leaf&#x27;: [1, 3, 5],\n",
       "                         &#x27;min_samples_split&#x27;: [0, 3, 2],\n",
       "                         &#x27;n_estimators&#x27;: [400, 700, 600]},\n",
       "             verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=2, estimator=RandomForestClassifier(), n_jobs=-1,\n",
       "             param_grid={'criterion': ['entropy', 'entropy'],\n",
       "                         'max_depth': [120], 'max_features': ['sqrt'],\n",
       "                         'min_samples_leaf': [1, 3, 5],\n",
       "                         'min_samples_split': [0, 3, 2],\n",
       "                         'n_estimators': [400, 700, 600]},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "grid_search = GridSearchCV(estimator= RandomForestClassifier() , param_grid = param_grid , cv = 2 , n_jobs = -1 , verbose = 2)\n",
    "grid_search.fit(x_train , y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'entropy',\n",
       " 'max_depth': 120,\n",
       " 'max_features': 'sqrt',\n",
       " 'min_samples_leaf': 5,\n",
       " 'min_samples_split': 2,\n",
       " 'n_estimators': 400}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7801302931596091"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, max_depth=500, max_features=&#x27;log2&#x27;,\n",
       "                       min_samples_leaf=5, min_samples_split=4,\n",
       "                       n_estimators=200)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" checked><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, max_depth=500, max_features=&#x27;log2&#x27;,\n",
       "                       min_samples_leaf=5, min_samples_split=4,\n",
       "                       n_estimators=200)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', max_depth=500, max_features='log2',\n",
       "                       min_samples_leaf=5, min_samples_split=4,\n",
       "                       n_estimators=200)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "me = RandomForestClassifier(n_estimators = 200, min_samples_split= 4, min_samples_leaf =  5, max_features = 'log2', max_depth = 500 , criterion = 'entropy')\n",
    "me.fit(x_train , y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7532467532467533"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_me = me.predict(x_test)\n",
    "accuracy_score(y_test , y_me)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automated Hyperparameter Tuning \n",
    "Automated Hyperparameter Tuning can be done by using techniques such as\n",
    "\n",
    "* Bayesian Optimization\n",
    "* Gradient Descent\n",
    "* Evolutionary Algorithms\n",
    "\n",
    "### Bayesian Optimization\n",
    "Bayesian optimization uses probability to find the minimum of a function. The final aim is to find the input value to a function which can gives us the lowest possible output value.It usually performs better than random,grid and manual search providing better performance in the testing phase and reduced optimization time. In Hyperopt, Bayesian Optimization can be implemented giving 3 three main parameters to the function fmin.\n",
    "\n",
    "* Objective Function = defines the loss function to minimize.\n",
    "* Domain Space = defines the range of input values to test (in Bayesian Optimization this space creates a probability distribution for each of the used Hyperparameters).\n",
    "* Optimization Algorithm = defines the search algorithm to use to select the best input values to use in each new iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp , fmin , tpe , STATUS_OK , Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "space = {\n",
    "         'criterion' : hp.choice('criterion' , ['entropy' , 'gini']),\n",
    "         'max_depth' : hp.quniform('maxdepth', 10 , 1200 , 10),\n",
    "         'max_features' : hp.choice('max_features', ['auto' , 'sqrt' , 'log2' , None]),\n",
    "         'min_samples_leaf' : hp.uniform('min_samples_leaf', 0 , 0.5),\n",
    "         'min_samples_split' : hp.uniform('min_samples_split', 0 , 1),\n",
    "         'n_estimators' : hp.choice('n_estimators', [10 , 50 , 300 , 750 , 1200])\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* hp.choice -> For Selecting \n",
    "* hp.quniform -> For Integers\n",
    "* hp.uniform -> For Floating numbers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "def objective(space) : \n",
    "    model = RandomForestClassifier(criterion= space['criterion'] , max_depth = space['max_depth'],\n",
    "        max_features= space['max_features'] , min_samples_leaf= space['min_samples_leaf'],\n",
    "        min_samples_split= space['min_samples_split'],\n",
    "        n_estimators= space['n_estimators'])\n",
    "    \n",
    "    accuracy = cross_val_score(model , x_train , y_train , cv = 5).mean()\n",
    "\n",
    "    # We aim to maximize accuracy , therefore we return it as a negaitve value\n",
    "    return {'loss' : -accuracy , 'status' : STATUS_OK}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/80 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "job exception: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kushalbanda/Anaconda/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kushalbanda/Anaconda/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/ensemble/_forest.py\", line 476, in fit\n",
      "    trees = Parallel(\n",
      "  File \"/Users/kushalbanda/Anaconda/anaconda3/envs/py310/lib/python3.10/site-packages/joblib/parallel.py\", line 1085, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/kushalbanda/Anaconda/anaconda3/envs/py310/lib/python3.10/site-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/kushalbanda/Anaconda/anaconda3/envs/py310/lib/python3.10/site-packages/joblib/parallel.py\", line 819, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/kushalbanda/Anaconda/anaconda3/envs/py310/lib/python3.10/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/kushalbanda/Anaconda/anaconda3/envs/py310/lib/python3.10/site-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/kushalbanda/Anaconda/anaconda3/envs/py310/lib/python3.10/site-packages/joblib/parallel.py\", line 288, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/kushalbanda/Anaconda/anaconda3/envs/py310/lib/python3.10/site-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/kushalbanda/Anaconda/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/utils/fixes.py\", line 117, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/kushalbanda/Anaconda/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/ensemble/_forest.py\", line 189, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/kushalbanda/Anaconda/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/tree/_classes.py\", line 969, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/kushalbanda/Anaconda/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/tree/_classes.py\", line 238, in fit\n",
      "    check_scalar(\n",
      "  File \"/Users/kushalbanda/Anaconda/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1452, in check_scalar\n",
      "    raise TypeError(\n",
      "TypeError: max_depth must be an instance of int, not float.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/80 [00:00<?, ?trial/s, best loss=?]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/Users/kushalbanda/Anaconda/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/Users/kushalbanda/Anaconda/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/ensemble/_forest.py\", line 476, in fit\n    trees = Parallel(\n  File \"/Users/kushalbanda/Anaconda/anaconda3/envs/py310/lib/python3.10/site-packages/joblib/parallel.py\", line 1085, in __call__\n    if self.dispatch_one_batch(iterator):\n  File \"/Users/kushalbanda/Anaconda/anaconda3/envs/py310/lib/python3.10/site-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n    self._dispatch(tasks)\n  File \"/Users/kushalbanda/Anaconda/anaconda3/envs/py310/lib/python3.10/site-packages/joblib/parallel.py\", line 819, in _dispatch\n    job = self._backend.apply_async(batch, callback=cb)\n  File \"/Users/kushalbanda/Anaconda/anaconda3/envs/py310/lib/python3.10/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n    result = ImmediateResult(func)\n  File \"/Users/kushalbanda/Anaconda/anaconda3/envs/py310/lib/python3.10/site-packages/joblib/_parallel_backends.py\", line 597, in __init__\n    self.results = batch()\n  File \"/Users/kushalbanda/Anaconda/anaconda3/envs/py310/lib/python3.10/site-packages/joblib/parallel.py\", line 288, in __call__\n    return [func(*args, **kwargs)\n  File \"/Users/kushalbanda/Anaconda/anaconda3/envs/py310/lib/python3.10/site-packages/joblib/parallel.py\", line 288, in <listcomp>\n    return [func(*args, **kwargs)\n  File \"/Users/kushalbanda/Anaconda/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/utils/fixes.py\", line 117, in __call__\n    return self.function(*args, **kwargs)\n  File \"/Users/kushalbanda/Anaconda/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/ensemble/_forest.py\", line 189, in _parallel_build_trees\n    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n  File \"/Users/kushalbanda/Anaconda/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/tree/_classes.py\", line 969, in fit\n    super().fit(\n  File \"/Users/kushalbanda/Anaconda/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/tree/_classes.py\", line 238, in fit\n    check_scalar(\n  File \"/Users/kushalbanda/Anaconda/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1452, in check_scalar\n    raise TypeError(\nTypeError: max_depth must be an instance of int, not float.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [41], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m trail \u001b[38;5;241m=\u001b[39m Trials()\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# fmin minimizes the function values\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m best \u001b[38;5;241m=\u001b[39m fmin(fn \u001b[38;5;241m=\u001b[39m objective,\n\u001b[1;32m      4\u001b[0m             space \u001b[38;5;241m=\u001b[39m space,\n\u001b[1;32m      5\u001b[0m             algo \u001b[38;5;241m=\u001b[39m tpe\u001b[38;5;241m.\u001b[39msuggest,\n\u001b[1;32m      6\u001b[0m             max_evals \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m80\u001b[39m,\n\u001b[1;32m      7\u001b[0m             trials\u001b[38;5;241m=\u001b[39m trail)\n\u001b[1;32m      9\u001b[0m best\n",
      "File \u001b[0;32m~/Anaconda/anaconda3/envs/py310/lib/python3.10/site-packages/hyperopt/fmin.py:540\u001b[0m, in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    537\u001b[0m     fn \u001b[39m=\u001b[39m __objective_fmin_wrapper(fn)\n\u001b[1;32m    539\u001b[0m \u001b[39mif\u001b[39;00m allow_trials_fmin \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(trials, \u001b[39m\"\u001b[39m\u001b[39mfmin\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 540\u001b[0m     \u001b[39mreturn\u001b[39;00m trials\u001b[39m.\u001b[39;49mfmin(\n\u001b[1;32m    541\u001b[0m         fn,\n\u001b[1;32m    542\u001b[0m         space,\n\u001b[1;32m    543\u001b[0m         algo\u001b[39m=\u001b[39;49malgo,\n\u001b[1;32m    544\u001b[0m         max_evals\u001b[39m=\u001b[39;49mmax_evals,\n\u001b[1;32m    545\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    546\u001b[0m         loss_threshold\u001b[39m=\u001b[39;49mloss_threshold,\n\u001b[1;32m    547\u001b[0m         max_queue_len\u001b[39m=\u001b[39;49mmax_queue_len,\n\u001b[1;32m    548\u001b[0m         rstate\u001b[39m=\u001b[39;49mrstate,\n\u001b[1;32m    549\u001b[0m         pass_expr_memo_ctrl\u001b[39m=\u001b[39;49mpass_expr_memo_ctrl,\n\u001b[1;32m    550\u001b[0m         verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m    551\u001b[0m         catch_eval_exceptions\u001b[39m=\u001b[39;49mcatch_eval_exceptions,\n\u001b[1;32m    552\u001b[0m         return_argmin\u001b[39m=\u001b[39;49mreturn_argmin,\n\u001b[1;32m    553\u001b[0m         show_progressbar\u001b[39m=\u001b[39;49mshow_progressbar,\n\u001b[1;32m    554\u001b[0m         early_stop_fn\u001b[39m=\u001b[39;49mearly_stop_fn,\n\u001b[1;32m    555\u001b[0m         trials_save_file\u001b[39m=\u001b[39;49mtrials_save_file,\n\u001b[1;32m    556\u001b[0m     )\n\u001b[1;32m    558\u001b[0m \u001b[39mif\u001b[39;00m trials \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    559\u001b[0m     \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(trials_save_file):\n",
      "File \u001b[0;32m~/Anaconda/anaconda3/envs/py310/lib/python3.10/site-packages/hyperopt/base.py:671\u001b[0m, in \u001b[0;36mTrials.fmin\u001b[0;34m(self, fn, space, algo, max_evals, timeout, loss_threshold, max_queue_len, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[39m# -- Stop-gap implementation!\u001b[39;00m\n\u001b[1;32m    667\u001b[0m \u001b[39m#    fmin should have been a Trials method in the first place\u001b[39;00m\n\u001b[1;32m    668\u001b[0m \u001b[39m#    but for now it's still sitting in another file.\u001b[39;00m\n\u001b[1;32m    669\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mfmin\u001b[39;00m \u001b[39mimport\u001b[39;00m fmin\n\u001b[0;32m--> 671\u001b[0m \u001b[39mreturn\u001b[39;00m fmin(\n\u001b[1;32m    672\u001b[0m     fn,\n\u001b[1;32m    673\u001b[0m     space,\n\u001b[1;32m    674\u001b[0m     algo\u001b[39m=\u001b[39;49malgo,\n\u001b[1;32m    675\u001b[0m     max_evals\u001b[39m=\u001b[39;49mmax_evals,\n\u001b[1;32m    676\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    677\u001b[0m     loss_threshold\u001b[39m=\u001b[39;49mloss_threshold,\n\u001b[1;32m    678\u001b[0m     trials\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m    679\u001b[0m     rstate\u001b[39m=\u001b[39;49mrstate,\n\u001b[1;32m    680\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m    681\u001b[0m     max_queue_len\u001b[39m=\u001b[39;49mmax_queue_len,\n\u001b[1;32m    682\u001b[0m     allow_trials_fmin\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,  \u001b[39m# -- prevent recursion\u001b[39;49;00m\n\u001b[1;32m    683\u001b[0m     pass_expr_memo_ctrl\u001b[39m=\u001b[39;49mpass_expr_memo_ctrl,\n\u001b[1;32m    684\u001b[0m     catch_eval_exceptions\u001b[39m=\u001b[39;49mcatch_eval_exceptions,\n\u001b[1;32m    685\u001b[0m     return_argmin\u001b[39m=\u001b[39;49mreturn_argmin,\n\u001b[1;32m    686\u001b[0m     show_progressbar\u001b[39m=\u001b[39;49mshow_progressbar,\n\u001b[1;32m    687\u001b[0m     early_stop_fn\u001b[39m=\u001b[39;49mearly_stop_fn,\n\u001b[1;32m    688\u001b[0m     trials_save_file\u001b[39m=\u001b[39;49mtrials_save_file,\n\u001b[1;32m    689\u001b[0m )\n",
      "File \u001b[0;32m~/Anaconda/anaconda3/envs/py310/lib/python3.10/site-packages/hyperopt/fmin.py:586\u001b[0m, in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    583\u001b[0m rval\u001b[39m.\u001b[39mcatch_eval_exceptions \u001b[39m=\u001b[39m catch_eval_exceptions\n\u001b[1;32m    585\u001b[0m \u001b[39m# next line is where the fmin is actually executed\u001b[39;00m\n\u001b[0;32m--> 586\u001b[0m rval\u001b[39m.\u001b[39;49mexhaust()\n\u001b[1;32m    588\u001b[0m \u001b[39mif\u001b[39;00m return_argmin:\n\u001b[1;32m    589\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(trials\u001b[39m.\u001b[39mtrials) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/Anaconda/anaconda3/envs/py310/lib/python3.10/site-packages/hyperopt/fmin.py:364\u001b[0m, in \u001b[0;36mFMinIter.exhaust\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mexhaust\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    363\u001b[0m     n_done \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrials)\n\u001b[0;32m--> 364\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_evals \u001b[39m-\u001b[39;49m n_done, block_until_done\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49masynchronous)\n\u001b[1;32m    365\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrials\u001b[39m.\u001b[39mrefresh()\n\u001b[1;32m    366\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/Anaconda/anaconda3/envs/py310/lib/python3.10/site-packages/hyperopt/fmin.py:300\u001b[0m, in \u001b[0;36mFMinIter.run\u001b[0;34m(self, N, block_until_done)\u001b[0m\n\u001b[1;32m    297\u001b[0m     time\u001b[39m.\u001b[39msleep(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpoll_interval_secs)\n\u001b[1;32m    298\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    299\u001b[0m     \u001b[39m# -- loop over trials and do the jobs directly\u001b[39;00m\n\u001b[0;32m--> 300\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mserial_evaluate()\n\u001b[1;32m    302\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrials\u001b[39m.\u001b[39mrefresh()\n\u001b[1;32m    303\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrials_save_file \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m~/Anaconda/anaconda3/envs/py310/lib/python3.10/site-packages/hyperopt/fmin.py:178\u001b[0m, in \u001b[0;36mFMinIter.serial_evaluate\u001b[0;34m(self, N)\u001b[0m\n\u001b[1;32m    176\u001b[0m ctrl \u001b[39m=\u001b[39m base\u001b[39m.\u001b[39mCtrl(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrials, current_trial\u001b[39m=\u001b[39mtrial)\n\u001b[1;32m    177\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 178\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdomain\u001b[39m.\u001b[39;49mevaluate(spec, ctrl)\n\u001b[1;32m    179\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    180\u001b[0m     logger\u001b[39m.\u001b[39merror(\u001b[39m\"\u001b[39m\u001b[39mjob exception: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m \u001b[39mstr\u001b[39m(e))\n",
      "File \u001b[0;32m~/Anaconda/anaconda3/envs/py310/lib/python3.10/site-packages/hyperopt/base.py:892\u001b[0m, in \u001b[0;36mDomain.evaluate\u001b[0;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    884\u001b[0m     \u001b[39m# -- the \"work\" of evaluating `config` can be written\u001b[39;00m\n\u001b[1;32m    885\u001b[0m     \u001b[39m#    either into the pyll part (self.expr)\u001b[39;00m\n\u001b[1;32m    886\u001b[0m     \u001b[39m#    or the normal Python part (self.fn)\u001b[39;00m\n\u001b[1;32m    887\u001b[0m     pyll_rval \u001b[39m=\u001b[39m pyll\u001b[39m.\u001b[39mrec_eval(\n\u001b[1;32m    888\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexpr,\n\u001b[1;32m    889\u001b[0m         memo\u001b[39m=\u001b[39mmemo,\n\u001b[1;32m    890\u001b[0m         print_node_on_error\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrec_eval_print_node_on_error,\n\u001b[1;32m    891\u001b[0m     )\n\u001b[0;32m--> 892\u001b[0m     rval \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfn(pyll_rval)\n\u001b[1;32m    894\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(rval, (\u001b[39mfloat\u001b[39m, \u001b[39mint\u001b[39m, np\u001b[39m.\u001b[39mnumber)):\n\u001b[1;32m    895\u001b[0m     dict_rval \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mfloat\u001b[39m(rval), \u001b[39m\"\u001b[39m\u001b[39mstatus\u001b[39m\u001b[39m\"\u001b[39m: STATUS_OK}\n",
      "Cell \u001b[0;32mIn [40], line 8\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(space)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mobjective\u001b[39m(space) : \n\u001b[1;32m      3\u001b[0m     model \u001b[38;5;241m=\u001b[39m RandomForestClassifier(criterion\u001b[38;5;241m=\u001b[39m space[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcriterion\u001b[39m\u001b[38;5;124m'\u001b[39m] , max_depth \u001b[38;5;241m=\u001b[39m space[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m      4\u001b[0m         max_features\u001b[38;5;241m=\u001b[39m space[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_features\u001b[39m\u001b[38;5;124m'\u001b[39m] , min_samples_leaf\u001b[38;5;241m=\u001b[39m space[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin_samples_leaf\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m      5\u001b[0m         min_samples_split\u001b[38;5;241m=\u001b[39m space[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin_samples_split\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m      6\u001b[0m         n_estimators\u001b[38;5;241m=\u001b[39m space[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m----> 8\u001b[0m     accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m# We aim to maximize accuracy , therefore we return it as a negaitve value\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m : \u001b[38;5;241m-\u001b[39maccuracy , \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m'\u001b[39m : STATUS_OK}\n",
      "File \u001b[0;32m~/Anaconda/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:515\u001b[0m, in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[39m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[1;32m    513\u001b[0m scorer \u001b[39m=\u001b[39m check_scoring(estimator, scoring\u001b[39m=\u001b[39mscoring)\n\u001b[0;32m--> 515\u001b[0m cv_results \u001b[39m=\u001b[39m cross_validate(\n\u001b[1;32m    516\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[1;32m    517\u001b[0m     X\u001b[39m=\u001b[39;49mX,\n\u001b[1;32m    518\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[1;32m    519\u001b[0m     groups\u001b[39m=\u001b[39;49mgroups,\n\u001b[1;32m    520\u001b[0m     scoring\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mscore\u001b[39;49m\u001b[39m\"\u001b[39;49m: scorer},\n\u001b[1;32m    521\u001b[0m     cv\u001b[39m=\u001b[39;49mcv,\n\u001b[1;32m    522\u001b[0m     n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[1;32m    523\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m    524\u001b[0m     fit_params\u001b[39m=\u001b[39;49mfit_params,\n\u001b[1;32m    525\u001b[0m     pre_dispatch\u001b[39m=\u001b[39;49mpre_dispatch,\n\u001b[1;32m    526\u001b[0m     error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[1;32m    527\u001b[0m )\n\u001b[1;32m    528\u001b[0m \u001b[39mreturn\u001b[39;00m cv_results[\u001b[39m\"\u001b[39m\u001b[39mtest_score\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Anaconda/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:285\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    265\u001b[0m parallel \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39mn_jobs, verbose\u001b[39m=\u001b[39mverbose, pre_dispatch\u001b[39m=\u001b[39mpre_dispatch)\n\u001b[1;32m    266\u001b[0m results \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    267\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    268\u001b[0m         clone(estimator),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    282\u001b[0m     \u001b[39mfor\u001b[39;00m train, test \u001b[39min\u001b[39;00m cv\u001b[39m.\u001b[39msplit(X, y, groups)\n\u001b[1;32m    283\u001b[0m )\n\u001b[0;32m--> 285\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[1;32m    287\u001b[0m \u001b[39m# For callabe scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[39m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[1;32m    289\u001b[0m \u001b[39m# the correct key.\u001b[39;00m\n\u001b[1;32m    290\u001b[0m \u001b[39mif\u001b[39;00m callable(scoring):\n",
      "File \u001b[0;32m~/Anaconda/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:367\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[0;34m(results, error_score)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[39mif\u001b[39;00m num_failed_fits \u001b[39m==\u001b[39m num_fits:\n\u001b[1;32m    361\u001b[0m     all_fits_failed_message \u001b[39m=\u001b[39m (\n\u001b[1;32m    362\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mAll the \u001b[39m\u001b[39m{\u001b[39;00mnum_fits\u001b[39m}\u001b[39;00m\u001b[39m fits failed.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    363\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mIt is very likely that your model is misconfigured.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    364\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mYou can try to debug the error by setting error_score=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    365\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBelow are more details about the failures:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mfit_errors_summary\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    366\u001b[0m     )\n\u001b[0;32m--> 367\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[1;32m    369\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    370\u001b[0m     some_fits_failed_message \u001b[39m=\u001b[39m (\n\u001b[1;32m    371\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mnum_failed_fits\u001b[39m}\u001b[39;00m\u001b[39m fits failed out of a total of \u001b[39m\u001b[39m{\u001b[39;00mnum_fits\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    372\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe score on these train-test partitions for these parameters\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBelow are more details about the failures:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mfit_errors_summary\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    377\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: \nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/Users/kushalbanda/Anaconda/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/Users/kushalbanda/Anaconda/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/ensemble/_forest.py\", line 476, in fit\n    trees = Parallel(\n  File \"/Users/kushalbanda/Anaconda/anaconda3/envs/py310/lib/python3.10/site-packages/joblib/parallel.py\", line 1085, in __call__\n    if self.dispatch_one_batch(iterator):\n  File \"/Users/kushalbanda/Anaconda/anaconda3/envs/py310/lib/python3.10/site-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n    self._dispatch(tasks)\n  File \"/Users/kushalbanda/Anaconda/anaconda3/envs/py310/lib/python3.10/site-packages/joblib/parallel.py\", line 819, in _dispatch\n    job = self._backend.apply_async(batch, callback=cb)\n  File \"/Users/kushalbanda/Anaconda/anaconda3/envs/py310/lib/python3.10/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n    result = ImmediateResult(func)\n  File \"/Users/kushalbanda/Anaconda/anaconda3/envs/py310/lib/python3.10/site-packages/joblib/_parallel_backends.py\", line 597, in __init__\n    self.results = batch()\n  File \"/Users/kushalbanda/Anaconda/anaconda3/envs/py310/lib/python3.10/site-packages/joblib/parallel.py\", line 288, in __call__\n    return [func(*args, **kwargs)\n  File \"/Users/kushalbanda/Anaconda/anaconda3/envs/py310/lib/python3.10/site-packages/joblib/parallel.py\", line 288, in <listcomp>\n    return [func(*args, **kwargs)\n  File \"/Users/kushalbanda/Anaconda/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/utils/fixes.py\", line 117, in __call__\n    return self.function(*args, **kwargs)\n  File \"/Users/kushalbanda/Anaconda/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/ensemble/_forest.py\", line 189, in _parallel_build_trees\n    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n  File \"/Users/kushalbanda/Anaconda/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/tree/_classes.py\", line 969, in fit\n    super().fit(\n  File \"/Users/kushalbanda/Anaconda/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/tree/_classes.py\", line 238, in fit\n    check_scalar(\n  File \"/Users/kushalbanda/Anaconda/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1452, in check_scalar\n    raise TypeError(\nTypeError: max_depth must be an instance of int, not float.\n"
     ]
    }
   ],
   "source": [
    "trail = Trials()\n",
    "# fmin minimizes the function values\n",
    "best = fmin(fn = objective,\n",
    "            space = space,\n",
    "            algo = tpe.suggest,\n",
    "            max_evals = 80,\n",
    "            trials= trail)\n",
    "\n",
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=160, max_features=None,\n",
       "                       min_samples_leaf=0.035426869579208625,\n",
       "                       min_samples_split=0.0032947923955915018, n_estimators=2)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_forest = RandomForestClassifier(criterion= 'gini' , max_features= None,\n",
    "max_depth= 160 , min_samples_split= 0.0032947923955915018,\n",
    "min_samples_leaf= 0.035426869579208625, n_estimators= 2)\n",
    "trained_forest.fit(x_train , y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7467532467532467"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = trained_forest.predict(x_test)\n",
    "accuracy_score(y_test , y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('py310')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cdbc327dcd34d5d05a76375c004ab359e51ae234710dbb053bfc778f4617c129"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
